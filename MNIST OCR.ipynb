{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = mnist.load_data() #Loading handwritten digits dataset with 28x28 images (labelled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train #Splitting data into images and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #Displaying the image using plotting library\n",
    "plt.imshow(X_test[0],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data to bring in range 0 to 1 from 0 to 255\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #Flattened the images from 28x28 to 784 to feed to neural network neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Making a feed-forward artificial neural network with sequential layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers and activations\n",
    "model.add(Dense(128,activation='relu',input_shape=(784,)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#Categorical crossentropy is used to define error for multiple classes (0 to 9 in this case)\n",
    "#Adam optimizer uses a combination of RMSProp and Gradient Descent Optimization technique\n",
    "#We are judging the model on its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "48/48 [==============================] - 1s 22ms/step - loss: 1.1930 - accuracy: 0.6294 - val_loss: 0.4704 - val_accuracy: 0.8708\n",
      "Epoch 2/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3669 - accuracy: 0.8996 - val_loss: 0.2676 - val_accuracy: 0.9277\n",
      "Epoch 3/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2478 - accuracy: 0.9310 - val_loss: 0.2050 - val_accuracy: 0.9437\n",
      "Epoch 4/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1941 - accuracy: 0.9452 - val_loss: 0.1765 - val_accuracy: 0.9517\n",
      "Epoch 5/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1596 - accuracy: 0.9545 - val_loss: 0.1513 - val_accuracy: 0.9568\n",
      "Epoch 6/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.9606 - val_loss: 0.1429 - val_accuracy: 0.9582\n",
      "Epoch 7/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1184 - accuracy: 0.9662 - val_loss: 0.1368 - val_accuracy: 0.9605\n",
      "Epoch 8/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 0.9696 - val_loss: 0.1284 - val_accuracy: 0.9628\n",
      "Epoch 9/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0937 - accuracy: 0.9732 - val_loss: 0.1170 - val_accuracy: 0.9665\n",
      "Epoch 10/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9757 - val_loss: 0.1188 - val_accuracy: 0.9647\n",
      "Epoch 11/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0753 - accuracy: 0.9782 - val_loss: 0.1136 - val_accuracy: 0.9676\n",
      "Epoch 12/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0671 - accuracy: 0.9811 - val_loss: 0.1107 - val_accuracy: 0.9666\n",
      "Epoch 13/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.9829 - val_loss: 0.1074 - val_accuracy: 0.9681\n",
      "Epoch 14/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 0.1058 - val_accuracy: 0.9693\n",
      "Epoch 15/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.1046 - val_accuracy: 0.9679\n",
      "Epoch 16/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9881 - val_loss: 0.1015 - val_accuracy: 0.9703\n",
      "Epoch 17/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9899 - val_loss: 0.1039 - val_accuracy: 0.9708\n",
      "Epoch 18/40\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0366 - accuracy: 0.9904 - val_loss: 0.1046 - val_accuracy: 0.9698\n",
      "Epoch 19/40\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.0335 - accuracy: 0.9914 - val_loss: 0.1024 - val_accuracy: 0.9712\n",
      "Epoch 20/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9925 - val_loss: 0.1062 - val_accuracy: 0.9704\n",
      "Epoch 21/40\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.1055 - val_accuracy: 0.9710\n",
      "Epoch 22/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9943 - val_loss: 0.1038 - val_accuracy: 0.9718\n",
      "Epoch 23/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.1061 - val_accuracy: 0.9711\n",
      "Epoch 24/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.1050 - val_accuracy: 0.9714\n",
      "Epoch 25/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 0.1046 - val_accuracy: 0.9724\n",
      "Epoch 26/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.1071 - val_accuracy: 0.9721\n",
      "Epoch 27/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.1084 - val_accuracy: 0.9718\n",
      "Epoch 28/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 0.1095 - val_accuracy: 0.9716\n",
      "Epoch 29/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.1110 - val_accuracy: 0.9707\n",
      "Epoch 30/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.1107 - val_accuracy: 0.9718\n",
      "Epoch 31/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.1129 - val_accuracy: 0.9715\n",
      "Epoch 32/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.1151 - val_accuracy: 0.9722\n",
      "Epoch 33/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.1129 - val_accuracy: 0.9730\n",
      "Epoch 34/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.1203 - val_accuracy: 0.9715\n",
      "Epoch 35/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.1179 - val_accuracy: 0.9721\n",
      "Epoch 36/40\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.1186 - val_accuracy: 0.9720\n",
      "Epoch 37/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.1206 - val_accuracy: 0.9716\n",
      "Epoch 38/40\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.1218 - val_accuracy: 0.9712\n",
      "Epoch 39/40\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.1212 - val_accuracy: 0.9725\n",
      "Epoch 40/40\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.1227 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23b8d086cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model using the training data\n",
    "model.fit(X_train,Y_train,batch_size=1000,epochs=40,validation_split=0.2)\n",
    "#All the above parameters in fit function are hyperparameters, change them and experiment with them to see what different results can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating test accuracy\n",
    "import numpy as np\n",
    "total = len(X_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "corr=0\n",
    "for i in range(len(X_test)):\n",
    "    if np.argmax(Y_pred[i]) == np.argmax(Y_test[i]):\n",
    "        corr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = corr/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#working of argmax\n",
    "np.argmax(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
